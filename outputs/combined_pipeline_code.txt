# --- DATASATTE LITE REDDIT EXPLORER ---

# scripts/verify_db.py

# scripts/verify_db.py
import sqlite3
from pathlib import Path

DB_PATH = Path("../data/wgu_reddit_filtered.db")

def main():
    if not DB_PATH.exists():
        print(f"Database not found: {DB_PATH}")
        return

    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()

    print("\nTables:")
    c.execute("SELECT name FROM sqlite_master WHERE type IN ('table','view') ORDER BY 1;")
    print([r[0] for r in c.fetchall()])

    print("\nSchema for filtered_posts:")
    for col in c.execute("PRAGMA table_info(filtered_posts)"):
        print(f"- {col[1]} ({col[2]})")

    print("\nIntegrity check:")
    print(c.execute("PRAGMA integrity_check").fetchone()[0])

    print("\nRow counts:")
    posts = c.execute("SELECT COUNT(*) FROM filtered_posts").fetchone()[0]
    fts   = c.execute("SELECT COUNT(*) FROM filtered_posts_fts").fetchone()[0]
    print({"filtered_posts": posts, "filtered_posts_fts": fts})

    print("\nSample rows:")
    for r in c.execute("SELECT post_id, course_code, datetime(created_utc,'unixepoch') AS created_at, substr(title,1,60) FROM filtered_posts LIMIT 5;"):
        print(r)

    print("\nSample FTS search:")
    q = "wgu"
    sql = """
      SELECT fp.post_id, fp.course_code, substr(fp.title,1,60)
      FROM filtered_posts_fts f
      JOIN filtered_posts fp ON fp.rowid = f.rowid
      WHERE filtered_posts_fts MATCH ?
      LIMIT 5
    """
    for r in c.execute(sql, (q,)):
        print(r)

    conn.close()

if __name__ == "__main__":
    main()

# scripts/prepare_db.sql

PRAGMA foreign_keys = ON;
PRAGMA journal_mode = WAL;
PRAGMA synchronous = NORMAL;

-- lean indexes
CREATE INDEX IF NOT EXISTS idx_posts_course ON filtered_posts(course_code);

-- external-content FTS5: tiny and rebuildable
DROP TABLE IF EXISTS filtered_posts_fts;
CREATE VIRTUAL TABLE filtered_posts_fts USING fts5(
  title,
  selftext,
  content='filtered_posts',
  content_rowid='rowid',
  detail=none
);

-- build from content table
INSERT INTO filtered_posts_fts(filtered_posts_fts) VALUES('rebuild');

-- sync triggers
DROP TRIGGER IF EXISTS filtered_posts_ai;
DROP TRIGGER IF EXISTS filtered_posts_ad;
DROP TRIGGER IF EXISTS filtered_posts_au;

CREATE TRIGGER filtered_posts_ai AFTER INSERT ON filtered_posts BEGIN
  INSERT INTO filtered_posts_fts(rowid, title, selftext)
  VALUES (new.rowid, COALESCE(new.title,''), COALESCE(new.selftext,''));
END;

CREATE TRIGGER filtered_posts_ad AFTER DELETE ON filtered_posts BEGIN
  INSERT INTO filtered_posts_fts(filtered_posts_fts, rowid) VALUES ('delete', old.rowid);
END;

CREATE TRIGGER filtered_posts_au AFTER UPDATE ON filtered_posts BEGIN
  INSERT INTO filtered_posts_fts(filtered_posts_fts, rowid) VALUES ('delete', old.rowid);
  INSERT INTO filtered_posts_fts(rowid, title, selftext)
  VALUES (new.rowid, COALESCE(new.title,''), COALESCE(new.selftext,''));
END;

-- compact browse view (keep small)
DROP VIEW IF EXISTS filtered_posts_view;
CREATE VIEW filtered_posts_view AS
SELECT
  post_id,
  course_code,
  sentiment,
  datetime(created_utc,'unixepoch') AS created_at,
  title,
  selftext,
  permalink
FROM filtered_posts;

PRAGMA optimize;

# scripts/prepare_db.py

# scripts/prepare_db.py
import sqlite3
from pathlib import Path

BASE = Path(__file__).resolve().parent.parent
DB   = BASE / "data" / "wgu_reddit_filtered.db"
SQL  = BASE / "scripts" / "prepare_db.sql"

def _table_sql(con, name):
    row = con.execute("SELECT sql FROM sqlite_master WHERE type='table' AND name=?", (name,)).fetchone()
    return row[0] if row else ""

def _columns(con, name):
    return [r[1] for r in con.execute(f"PRAGMA table_info({name})")]

def _needs_migration(con) -> bool:
    sql = _table_sql(con, "filtered_posts").upper()
    cols = set(_columns(con, "filtered_posts"))
    if not sql:
        return False
    # migrate if WITHOUT ROWID, or missing post_id, or has legacy id PK
    return ("WITHOUT ROWID" in sql) or ("POST_ID" not in cols) or ("ID" in cols)

def _auto_migrate(con):
    if not _needs_migration(con):
        return
    con.execute("PRAGMA foreign_keys=OFF")
    con.execute("BEGIN")
    try:
        con.execute("""
          CREATE TABLE filtered_posts_new (
            post_id   TEXT UNIQUE NOT NULL,
            subreddit TEXT NOT NULL,
            course_code TEXT NOT NULL,
            sentiment REAL,
            created_utc INTEGER NOT NULL,
            title TEXT,
            selftext TEXT,
            text_clean TEXT,
            text_length INTEGER,
            score INTEGER,
            permalink TEXT
          ); -- WITH rowid
        """)
        src_cols = set(_columns(con, "filtered_posts"))
        # map old column names if present
        id_expr = "post_id" if "post_id" in src_cols else ("id" if "id" in src_cols else "NULL")
        course_expr = "course_code" if "course_code" in src_cols else "NULL"
        select_sql = f"""
          SELECT
            {id_expr} AS post_id,
            subreddit,
            {course_expr} AS course_code,
            sentiment,
            created_utc,
            title,
            selftext,
            text_clean,
            text_length,
            score,
            permalink
          FROM filtered_posts
        """
        con.execute(f"""
          INSERT INTO filtered_posts_new
          (post_id, subreddit, course_code, sentiment, created_utc, title, selftext, text_clean, text_length, score, permalink)
          {select_sql}
        """)
        con.execute("DROP TABLE filtered_posts;")
        con.execute("ALTER TABLE filtered_posts_new RENAME TO filtered_posts;")
        con.execute("COMMIT")
    except Exception:
        con.execute("ROLLBACK")
        raise
    finally:
        con.execute("PRAGMA foreign_keys=ON")

def main():
    if not DB.exists():
        raise FileNotFoundError(DB)
    if not SQL.exists():
        raise FileNotFoundError(SQL)

    with sqlite3.connect(DB) as con:
        _auto_migrate(con)

        with open(SQL, "r", encoding="utf-8") as f:
            con.executescript(f.read())

        con.execute("PRAGMA wal_checkpoint(FULL)")
        con.execute("VACUUM")

        posts = con.execute("SELECT COUNT(*) FROM filtered_posts").fetchone()[0]
        fts   = con.execute("SELECT COUNT(*) FROM filtered_posts_fts").fetchone()[0]
        fk    = con.execute("PRAGMA foreign_keys").fetchone()[0]
        wal   = con.execute("PRAGMA journal_mode").fetchone()[0]
        sync  = con.execute("PRAGMA synchronous").fetchone()[0]
        print(f"{DB.name}: prepared")
        print(f"  rows: filtered_posts={posts}, filtered_posts_fts={fts}")
        print(f"  pragmas: foreign_keys={fk}, journal_mode={wal}, synchronous={sync}")

if __name__ == "__main__":
    main()

# scripts/build_db.py

# scripts/build_db.py
import json, sqlite3, sys
from pathlib import Path

BASE = Path(__file__).resolve().parent.parent
DATA = BASE / "data"
INPUT_FILE = DATA / "filtered_posts_with_metadata.jsonl"
OUTPUT_DB  = DATA / "wgu_reddit_filtered.db"

STRICT = True  # skip rows with missing/empty course_code

def _norm_str(x):
    return x.strip() if isinstance(x, str) else x

def _first_nonempty(iterable):
    if not iterable:
        return None
    for v in iterable:
        s = _norm_str(v)
        if isinstance(s, str) and s:
            return s
    return None

def _extract_course_code(p):
    # Try multiple fields; accept string or list
    candidates = []
    # singular
    if isinstance(p.get("course_code"), str):
        candidates.append(p.get("course_code"))
    # plural common variants
    for key in ("matched_course_codes", "course_codes", "courses"):
        val = p.get(key)
        if isinstance(val, list):
            candidates.extend(val)
        elif isinstance(val, str):
            candidates.append(val)
    return _first_nonempty(candidates)

def build():
    if not INPUT_FILE.exists():
        print(f"Input not found: {INPUT_FILE}", file=sys.stderr)
        sys.exit(1)

    OUTPUT_DB.parent.mkdir(parents=True, exist_ok=True)
    con = sqlite3.connect(OUTPUT_DB)
    cur = con.cursor()

    cur.executescript("""
        PRAGMA foreign_keys=ON;
        PRAGMA journal_mode=WAL;
        PRAGMA synchronous=NORMAL;

        DROP TABLE IF EXISTS filtered_posts;
        CREATE TABLE filtered_posts (
          -- implicit rowid is used by FTS
          post_id     TEXT UNIQUE NOT NULL,
          subreddit   TEXT NOT NULL,
          course_code TEXT {nullness},
          sentiment   REAL,
          created_utc INTEGER NOT NULL,
          title       TEXT,
          selftext    TEXT,
          text_clean  TEXT,
          text_length INTEGER,
          score       INTEGER,
          permalink   TEXT
        );
    """.format(nullness="NOT NULL" if STRICT else ""))

    rows = []
    total = 0
    skipped_no_course = 0
    sample_skips = []

    with INPUT_FILE.open("r", encoding="utf-8") as f:
        for line in f:
            if not line.strip():
                continue
            total += 1
            p = json.loads(line)

            course_code = _extract_course_code(p)
            if STRICT and not course_code:
                skipped_no_course += 1
                if len(sample_skips) < 5:
                    sample_skips.append({
                        "post_id": p.get("post_id"),
                        "keys_present": [k for k in ("course_code","matched_course_codes","course_codes","courses") if k in p],
                        "values": {k: p.get(k) for k in ("course_code","matched_course_codes","course_codes","courses")}
                    })
                continue

            rows.append((
                p["post_id"],
                _norm_str(p.get("subreddit") or "") or "unknown",
                course_code,
                p.get("VADER_Compound"),
                int(p["created_utc"]),
                p.get("title"),
                p.get("selftext"),
                p.get("text_clean"),
                p.get("text_length"),
                p.get("score"),
                p.get("permalink"),
            ))

    if rows:
        cur.executemany("""
          INSERT INTO filtered_posts
          (post_id, subreddit, course_code, sentiment, created_utc,
           title, selftext, text_clean, text_length, score, permalink)
          VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, rows)

    cur.executescript("""
      CREATE INDEX IF NOT EXISTS idx_posts_course ON filtered_posts(course_code);
      -- CREATE INDEX IF NOT EXISTS idx_posts_created ON filtered_posts(created_utc DESC);
    """)

    con.commit()
    n = cur.execute("SELECT COUNT(*) FROM filtered_posts").fetchone()[0]
    print(f"Built {OUTPUT_DB.name} with {n} rows")
    print(f"Input rows: {total}")
    print(f"Skipped (missing/empty course_code): {skipped_no_course}")
    if sample_skips:
        print("Sample skipped rows (first 5):")
        for s in sample_skips:
            print(s)

    con.close()

if __name__ == "__main__":
    build()

